{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, Bidirectional, LSTM, GRU, Input, GlobalMaxPooling1D, LayerNormalization, Conv1D, MaxPooling1D, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pyvi import ViTokenizer, ViUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA ACHIEVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('texts.xlsx')\n",
    "sentiment_data = pd.DataFrame({'input': data['BriefContent'], 'label': data['Sentiment']}).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = sentiment_data['input'].values\n",
    "input_label = sentiment_data['label'].values\n",
    "label_dict = {'Tiêu cực': 0, 'Trung lập': 1, 'Tích cực': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Document Processing and Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pre = []\n",
    "label_with_accent = []\n",
    "for idx, dt in enumerate(input_data):\n",
    "    input_text_pre = list(tf.keras.preprocessing.text.text_to_word_sequence(dt))\n",
    "    input_text_pre = \" \".join(input_text_pre)\n",
    "    input_text_pre_no_accent = str(ViUtils.remove_accents(input_text_pre).decode(\"utf-8\"))\n",
    "    input_text_pre_accent = ViTokenizer.tokenize(input_text_pre)\n",
    "    input_text_pre_no_accent = ViTokenizer.tokenize(input_text_pre_no_accent)\n",
    "    \n",
    "    input_pre.append(input_text_pre_accent)\n",
    "    input_pre.append(input_text_pre_no_accent)\n",
    "    label_with_accent.append(input_label[idx])\n",
    "    label_with_accent.append(input_label[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Number of Words and Graph String Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 6500, 1000):\n",
    "    seq_len = [len(j.split()) for j in input_pre[i:i+1000]]\n",
    "    pd.Series(seq_len).hist(bins=10)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = [label_dict[i] for i in label_with_accent]\n",
    "label_tf = tf.keras.utils.to_categorical(label_idx, num_classes=3, dtype='float32')\n",
    "\n",
    "tokenizer_data = Tokenizer(oov_token='<OOV>', filters=\"''\", split=' ')\n",
    "tokenizer_data.fit_on_texts(input_pre)\n",
    "tokenized_data_text = tokenizer_data.texts_to_sequences(input_pre)\n",
    "vec_data = pad_sequences(tokenized_data_text, padding='post', maxlen=512)\n",
    "\n",
    "pickle.dump(tokenizer_data, open(\"tokenizer_data.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Split Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(vec_data, label_tf, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "    dropout_threshold = 0.4\n",
    "    input_dim = len(tokenizer_data.word_index) + 1\n",
    "    output_dim = 32\n",
    "    input_length = 512\n",
    "    initializer = tf.keras.initializers.GlorotNormal()\n",
    "\n",
    "    input_layer = Input(shape=(input_length,))\n",
    "    feature = Embedding(input_dim=input_dim, output_dim=output_dim, input_length=input_length, embeddings_initializer=initializer)(input_layer)\n",
    "\n",
    "    cnn_feature = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(feature)\n",
    "    cnn_feature = MaxPooling1D()(cnn_feature)\n",
    "    cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n",
    "    cnn_feature = Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')(cnn_feature)\n",
    "    cnn_feature = MaxPooling1D()(cnn_feature)\n",
    "    cnn_feature = LayerNormalization()(cnn_feature)\n",
    "    cnn_feature = Dropout(dropout_threshold)(cnn_feature)\n",
    "\n",
    "    bi_lstm_feature = Bidirectional(LSTM(units=32, dropout=dropout_threshold, return_sequences=True, kernel_initializer=initializer))(cnn_feature)\n",
    "    bi_lstm_feature = MaxPooling1D()(bi_lstm_feature)\n",
    "    bi_lstm_feature = Bidirectional(GRU(units=32, dropout=dropout_threshold, return_sequences=True, kernel_initializer=initializer))(bi_lstm_feature)\n",
    "    bi_lstm_feature = MaxPooling1D()(bi_lstm_feature)\n",
    "    bi_lstm_feature = LayerNormalization()(bi_lstm_feature)\n",
    "\n",
    "    combine_feature = Concatenate()([cnn_feature, bi_lstm_feature])\n",
    "    combine_feature = GlobalMaxPooling1D()(combine_feature)\n",
    "    combine_feature = LayerNormalization()(combine_feature)\n",
    "\n",
    "    classifier = Dense(90, activation='relu')(combine_feature)\n",
    "    classifier = Dropout(0.2)(classifier)\n",
    "    classifier = Dense(70, activation='relu')(classifier)\n",
    "    classifier = Dropout(0.2)(classifier)\n",
    "    classifier = Dense(50, activation='relu')(classifier)\n",
    "    classifier = Dropout(0.2)(classifier)\n",
    "    classifier = Dense(30, activation='relu')(classifier)\n",
    "    classifier = Dropout(0.2)(classifier)\n",
    "    classifier = Dense(3, activation='softmax')(classifier)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input_layer, outputs=classifier)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=128, callbacks=[callback_model])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(raw_input, tokenizer, model):\n",
    "    input_model = preprocess_raw_input(raw_input, tokenizer)\n",
    "    result, conf = inference_model(input_model, model)\n",
    "    return result, conf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction(\"sua chua ngon lam\", my_tokenizer, my_model))\n",
    "while True:\n",
    "    text = input()\n",
    "    if text == \"end\":\n",
    "        break\n",
    "    else:\n",
    "        print(prediction(text, my_tokenizer, my_model)[0] + \"\\n\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
